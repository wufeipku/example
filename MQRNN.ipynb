{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T09:16:20.157727Z",
     "start_time": "2024-02-18T09:16:14.625279Z"
    },
    "execution": {
     "iopub.execute_input": "2023-01-10T06:54:29.893743Z",
     "iopub.status.busy": "2023-01-10T06:54:29.893322Z",
     "iopub.status.idle": "2023-01-10T06:54:30.618207Z",
     "shell.execute_reply": "2023-01-10T06:54:30.617115Z",
     "shell.execute_reply.started": "2023-01-10T06:54:29.893660Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from pandas import read_csv\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T09:16:26.599029Z",
     "start_time": "2024-02-18T09:16:26.577096Z"
    },
    "execution": {
     "iopub.execute_input": "2023-01-10T06:54:30.774640Z",
     "iopub.status.busy": "2023-01-10T06:54:30.773982Z",
     "iopub.status.idle": "2023-01-10T06:54:38.642682Z",
     "shell.execute_reply": "2023-01-10T06:54:38.641667Z",
     "shell.execute_reply.started": "2023-01-10T06:54:30.774594Z"
    }
   },
   "outputs": [],
   "source": [
    "name = 'LD2011_2014.txt'\n",
    "save_name = 'elect'\n",
    "num_covariates = 3\n",
    "train_start = '2011-01-01 00:00:00'\n",
    "train_end = '2014-08-31 23:00:00'\n",
    "test_start = '2014-08-24 00:00:00' #need additional 7 days as given info\n",
    "test_end = '2014-09-07 23:00:00'\n",
    "\n",
    "save_path = os.path.join('data', save_name)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "csv_path = os.path.join(save_path, name)\n",
    "if not os.path.exists(csv_path):\n",
    "    zipurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip'\n",
    "    with urlopen(zipurl) as zipresp:\n",
    "        with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "            zfile.extractall(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T01:42:32.249456Z",
     "start_time": "2024-02-19T01:42:23.750133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>...</th>\n",
       "      <th>MT_361</th>\n",
       "      <th>MT_362</th>\n",
       "      <th>MT_363</th>\n",
       "      <th>MT_364</th>\n",
       "      <th>MT_365</th>\n",
       "      <th>MT_366</th>\n",
       "      <th>MT_367</th>\n",
       "      <th>MT_368</th>\n",
       "      <th>MT_369</th>\n",
       "      <th>MT_370</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  MT_007  \\\n",
       "2011-01-01 00:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-01 00:30:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-01 00:45:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-01 01:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "                     MT_008  MT_009  MT_010  ...  MT_361  MT_362  MT_363  \\\n",
       "2011-01-01 00:15:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-01 00:30:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-01 00:45:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-01 01:00:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-01 01:15:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "\n",
       "                     MT_364  MT_365  MT_366  MT_367  MT_368  MT_369  MT_370  \n",
       "2011-01-01 00:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-01 00:30:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-01 00:45:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-01 01:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df = pd.read_csv(csv_path, sep=\";\", index_col=0, parse_dates=True, decimal=',')\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T09:16:40.508788Z",
     "start_time": "2024-02-18T09:16:28.742718Z"
    },
    "execution": {
     "iopub.execute_input": "2023-01-10T06:54:38.645782Z",
     "iopub.status.busy": "2023-01-10T06:54:38.645423Z",
     "iopub.status.idle": "2023-01-10T06:54:46.858712Z",
     "shell.execute_reply": "2023-01-10T06:54:46.857768Z",
     "shell.execute_reply.started": "2023-01-10T06:54:38.645746Z"
    }
   },
   "outputs": [],
   "source": [
    "# initial fixing\n",
    "# text_target_df的时序长度就是预测长度，即horizon_size;\n",
    "target_df = pd.read_csv(csv_path, sep=\";\", index_col=0, parse_dates=True, decimal=',')\n",
    "target_df = target_df.resample('12H',label = 'left',closed = 'right').sum()[train_start:test_end]\n",
    "target_df.fillna(0, inplace=True)\n",
    "\n",
    "train_target_df = target_df[train_start:train_end]\n",
    "test_target_df = target_df[test_start:test_end]\n",
    "horizon_size = test_target_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T09:16:41.858815Z",
     "start_time": "2024-02-18T09:16:41.820625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>...</th>\n",
       "      <th>MT_361</th>\n",
       "      <th>MT_362</th>\n",
       "      <th>MT_363</th>\n",
       "      <th>MT_364</th>\n",
       "      <th>MT_365</th>\n",
       "      <th>MT_366</th>\n",
       "      <th>MT_367</th>\n",
       "      <th>MT_368</th>\n",
       "      <th>MT_369</th>\n",
       "      <th>MT_370</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  MT_007  \\\n",
       "2011-01-01 00:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-01 12:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-02 00:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-02 12:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2011-01-03 00:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "                     MT_008  MT_009  MT_010  ...  MT_361  MT_362  MT_363  \\\n",
       "2011-01-01 00:00:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-01 12:00:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-02 00:00:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-02 12:00:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "2011-01-03 00:00:00     0.0     0.0     0.0  ...     0.0     0.0     0.0   \n",
       "\n",
       "                     MT_364  MT_365  MT_366  MT_367  MT_368  MT_369  MT_370  \n",
       "2011-01-01 00:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-01 12:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-02 00:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-02 12:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "2011-01-03 00:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T09:16:42.630097Z",
     "start_time": "2024-02-18T09:16:42.401928Z"
    },
    "execution": {
     "iopub.execute_input": "2023-01-10T06:54:46.872534Z",
     "iopub.status.busy": "2023-01-10T06:54:46.871640Z",
     "iopub.status.idle": "2023-01-10T06:54:46.998146Z",
     "shell.execute_reply": "2023-01-10T06:54:46.997141Z",
     "shell.execute_reply.started": "2023-01-10T06:54:46.872496Z"
    }
   },
   "outputs": [],
   "source": [
    "# 归一化目标值\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_target_df)\n",
    "train_target_df = pd.DataFrame(scaler.transform(train_target_df), index=train_target_df.index, columns=train_target_df.columns)\n",
    "test_target_df = pd.DataFrame(scaler.transform(test_target_df), index=test_target_df.index, columns=test_target_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T09:16:43.474482Z",
     "start_time": "2024-02-18T09:16:43.454151Z"
    },
    "execution": {
     "iopub.execute_input": "2023-01-10T06:54:47.000147Z",
     "iopub.status.busy": "2023-01-10T06:54:46.999682Z",
     "iopub.status.idle": "2023-01-10T06:54:47.015969Z",
     "shell.execute_reply": "2023-01-10T06:54:47.014937Z",
     "shell.execute_reply.started": "2023-01-10T06:54:47.000108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 12:00:00</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 12:00:00</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  dayofweek  month\n",
       "2011-01-01 00:00:00     0          5      1\n",
       "2011-01-01 12:00:00    12          5      1\n",
       "2011-01-02 00:00:00     0          6      1\n",
       "2011-01-02 12:00:00    12          6      1\n",
       "2011-01-03 00:00:00     0          0      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 提取小时、天、月份作为特征\n",
    "covariate_df = pd.DataFrame(index=target_df.index,\n",
    "                                data={'hour':target_df.index.hour,\n",
    "                                      'dayofweek':target_df.index.dayofweek,\n",
    "                                      'month': target_df.index.month\n",
    "                                })\n",
    "display(covariate_df.head())\n",
    "# 特征标准化\n",
    "for col in covariate_df.columns:\n",
    "        covariate_df[col] = (covariate_df[col] - np.mean(covariate_df[col]))/np.std(covariate_df[col])\n",
    "\n",
    "train_covariate_df = covariate_df[train_start:train_end]\n",
    "test_covariate_df = covariate_df[test_start:test_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T09:16:44.685669Z",
     "start_time": "2024-02-18T09:16:44.671635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.997681</td>\n",
       "      <td>-1.541571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 12:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997681</td>\n",
       "      <td>-1.541571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 00:00:00</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.497450</td>\n",
       "      <td>-1.541571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02 12:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.497450</td>\n",
       "      <td>-1.541571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03 00:00:00</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.501163</td>\n",
       "      <td>-1.541571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  dayofweek     month\n",
       "2011-01-01 00:00:00  -1.0   0.997681 -1.541571\n",
       "2011-01-01 12:00:00   1.0   0.997681 -1.541571\n",
       "2011-01-02 00:00:00  -1.0   1.497450 -1.541571\n",
       "2011-01-02 12:00:00   1.0   1.497450 -1.541571\n",
       "2011-01-03 00:00:00  -1.0  -1.501163 -1.541571"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:10:23.330312Z",
     "start_time": "2024-02-19T12:10:23.302501Z"
    },
    "execution": {
     "iopub.execute_input": "2023-01-10T06:54:47.027505Z",
     "iopub.status.busy": "2023-01-10T06:54:47.026796Z",
     "iopub.status.idle": "2023-01-10T06:54:48.660729Z",
     "shell.execute_reply": "2023-01-10T06:54:48.659715Z",
     "shell.execute_reply.started": "2023-01-10T06:54:47.027469Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "desired_quantiles = [0.25, 0.5, 0.75, 0.95]\n",
    "\n",
    "class MQRNN_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,\n",
    "                series_df:pd.DataFrame,\n",
    "                covariate_df:pd.DataFrame, \n",
    "                horizon_size:int=horizon_size,\n",
    "                quantile_size:int=len(desired_quantiles)):\n",
    "        \n",
    "        self.series_df = series_df\n",
    "        self.covariate_df = covariate_df\n",
    "        self.horizon_size = horizon_size\n",
    "        self.quantile_size = quantile_size\n",
    "        full_covariate = []\n",
    "        covariate_size = self.covariate_df.shape[1]\n",
    "        # 按horizon_size为窗口长度，划分特征数据为horizon*\n",
    "        for i in range(1, self.covariate_df.shape[0] - horizon_size+1):\n",
    "            cur_covariate = []\n",
    "            cur_covariate.append(self.covariate_df.iloc[i:i+horizon_size,:].to_numpy())\n",
    "#             cur_covariate = self.covariate_df.iloc[i:i+horizon_size,:].to_numpy()\n",
    "            full_covariate.append(cur_covariate)\n",
    "        full_covariate = np.array(full_covariate)\n",
    "        print(full_covariate.shape)\n",
    "        full_covariate = full_covariate.reshape(-1, horizon_size * covariate_size)\n",
    "        print(full_covariate.shape)\n",
    "        self.next_covariate = full_covariate\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.series_df.shape[1]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        cur_series = np.array(self.series_df.iloc[: -self.horizon_size, idx])\n",
    "        cur_covariate = np.array(self.covariate_df.iloc[:-self.horizon_size, :]) # covariate used in generating hidden states\n",
    "\n",
    "        covariate_size = self.covariate_df.shape[1]\n",
    "\n",
    "        # 真实值y，每组都是horizon_size的长度，这里时间序列就是1-30,2-31,3-32\n",
    "        real_vals_list = []\n",
    "        for i in range(1, self.horizon_size+1):\n",
    "            real_vals_list.append(np.array(self.series_df.iloc[i: self.series_df.shape[0]-self.horizon_size+i, idx]))\n",
    "        real_vals_array = np.array(real_vals_list) #[horizon_size, seq_len]\n",
    "        real_vals_array = real_vals_array.T #[seq_len, horizon_size]\n",
    "        \n",
    "        cur_series_tensor = torch.tensor(cur_series)\n",
    "        cur_series_tensor = torch.unsqueeze(cur_series_tensor,dim=1) # [seq_len, 1]\n",
    "        cur_covariate_tensor = torch.tensor(cur_covariate) #[seq_len, covariate_size]\n",
    "        # encoder的输入矩阵\n",
    "        cur_series_covariate_tensor = torch.cat([cur_series_tensor, cur_covariate_tensor],dim=1)\n",
    "        # decoder的输入矩阵\n",
    "        next_covariate_tensor = torch.tensor(self.next_covariate) #[seq_len, horizon_size * covariate_size]\n",
    "        # 真实值\n",
    "        cur_real_vals_tensor = torch.tensor(real_vals_array)\n",
    "        return cur_series_covariate_tensor, next_covariate_tensor, cur_real_vals_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:10:24.403776Z",
     "start_time": "2024-02-19T12:10:24.386648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2648, 90)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.next_covariate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:10:37.715347Z",
     "start_time": "2024-02-19T12:10:36.421069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2648, 1, 30, 3)\n",
      "(2648, 90)\n"
     ]
    }
   ],
   "source": [
    "data = MQRNN_dataset(train_target_df, train_covariate_df)\n",
    "# data.__getitem__(10)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T08:24:15.608160Z",
     "start_time": "2024-02-18T08:24:13.129775Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▉                                                                            | 2/24 [00:00<00:02,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▊                                                                     | 4/24 [00:00<00:02,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████▋                                                       | 8/24 [00:00<00:01,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▌                                            | 11/24 [00:01<00:01, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▍                                     | 13/24 [00:01<00:01,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████▎                              | 15/24 [00:01<00:00,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 18/24 [00:01<00:00,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████▎             | 20/24 [00:02<00:00,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████▏      | 22/24 [00:02<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "data_iter = DataLoader(dataset=data, batch_size=16, shuffle=True)\n",
    "pbar = tqdm(data_iter)\n",
    "for (cur_series_tensor, cur_covariate_tensor, cur_real_vals_tensor) in pbar:\n",
    "    batch_size, seq_len, horizon_size  = cur_series_tensor.shape[0], cur_series_tensor.shape[1], cur_covariate_tensor.shape[-1]\n",
    "    print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T08:34:17.287621Z",
     "start_time": "2024-02-18T08:34:17.267063Z"
    },
    "execution": {
     "iopub.execute_input": "2023-01-10T06:54:48.666687Z",
     "iopub.status.busy": "2023-01-10T06:54:48.666205Z",
     "iopub.status.idle": "2023-01-10T06:54:48.684984Z",
     "shell.execute_reply": "2023-01-10T06:54:48.683862Z",
     "shell.execute_reply.started": "2023-01-10T06:54:48.666656Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MQRNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                horizon_size:int=horizon_size, \n",
    "                hidden_size:int=100, \n",
    "                quantiles:list=desired_quantiles,\n",
    "                dropout:float=0.3,\n",
    "                layer_size:int=3,\n",
    "                context_size:int=50, \n",
    "                covariate_size:int=num_covariates,\n",
    "                bidirectional=False,\n",
    "                device=torch.device('cuda')):\n",
    "        super(MQRNN, self).__init__()\n",
    "        self.quantiles = desired_quantiles\n",
    "        self.quantile_size = len(quantiles)\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_size = hidden_size\n",
    "        self.horizon_size = horizon_size\n",
    "        self.device = device\n",
    "        self.covariate_size = covariate_size\n",
    "\n",
    "        self.encoder = nn.LSTM(input_size= covariate_size+1, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=layer_size, \n",
    "                            dropout=dropout,\n",
    "                            bidirectional=bidirectional)\n",
    "        self.global_decoder = nn.Sequential(nn.Linear(in_features= hidden_size + covariate_size*horizon_size, out_features= horizon_size*hidden_size*3),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(in_features= horizon_size*hidden_size*3, out_features= horizon_size*hidden_size*2),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(in_features= horizon_size*hidden_size*2, out_features= (horizon_size+1)*context_size),\n",
    "                                           nn.ReLU())\n",
    "        self.local_decoder = nn.Sequential(nn.Linear(in_features= horizon_size*context_size + horizon_size* covariate_size + context_size, out_features= horizon_size* context_size),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(in_features= horizon_size* context_size, out_features= horizon_size*self.quantile_size),\n",
    "                                           nn.ReLU())\n",
    "        self.encoder.double().to(self.device)\n",
    "        self.global_decoder.double().to(self.device)\n",
    "        self.local_decoder.double().to(self.device)\n",
    "        \n",
    "    def forward(self, cur_series_covariate_tensor, next_covariate_tensor):\n",
    "        seq_len, batch_size = cur_series_covariate_tensor.shape[0], cur_series_covariate_tensor.shape[1]\n",
    "        direction_size = 2 if self.bidirectional else 1\n",
    "        outputs,_ = self.encoder(cur_series_covariate_tensor)\n",
    "        outputs_reshape = outputs.view(seq_len,batch_size,direction_size,self.hidden_size)[:,:,-1,:]\n",
    "        encoder_outputs = outputs_reshape.view(seq_len,batch_size,self.hidden_size)\n",
    "        if not self.training:\n",
    "            encoder_outputs = torch.unsqueeze(encoder_outputs[-1],dim=0) #[1,1,hidden_size]\n",
    "\n",
    "        global_decoder_output = self.global_decoder(torch.cat([encoder_outputs, next_covariate_tensor], dim=2))\n",
    "        local_decoder_output = self.local_decoder(torch.cat([global_decoder_output, next_covariate_tensor], dim=2))\n",
    "        \n",
    "        seq_len = local_decoder_output.shape[0]\n",
    "        batch_size = local_decoder_output.shape[1]\n",
    "        return local_decoder_output.view(seq_len, batch_size, self.horizon_size, self.quantile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T08:34:18.684193Z",
     "start_time": "2024-02-18T08:34:18.669131Z"
    },
    "execution": {
     "iopub.execute_input": "2023-01-10T06:54:48.687057Z",
     "iopub.status.busy": "2023-01-10T06:54:48.686660Z",
     "iopub.status.idle": "2023-01-10T06:54:48.706036Z",
     "shell.execute_reply": "2023-01-10T06:54:48.705030Z",
     "shell.execute_reply.started": "2023-01-10T06:54:48.687019Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def train(model, train_dataset, desired_quantiles=desired_quantiles, batch_size=1, num_epochs=1, lr=1e-3, device=torch.device(\"cuda\")):\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    data_iter = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_sum = 0.0\n",
    "        total_sample = 0\n",
    "        pbar = tqdm(data_iter)\n",
    "        for (cur_series_tensor, cur_covariate_tensor, cur_real_vals_tensor) in pbar:\n",
    "            batch_size, seq_len, horizon_size  = cur_series_tensor.shape[0], cur_series_tensor.shape[1], cur_covariate_tensor.shape[-1]\n",
    "            total_sample += batch_size * seq_len * horizon_size\n",
    "            optimizer.zero_grad()\n",
    "            cur_series_covariate_tensor = cur_series_tensor.double().permute(1,0,2).to(device) #[seq_len, batch_size, 1+covariate_size]\n",
    "            next_covariate_tensor = cur_covariate_tensor.double().permute(1,0,2).to(device) #[seq_len, batch_size, covariate_size * horizon_size]\n",
    "            cur_real_vals_tensor = cur_real_vals_tensor.double().permute(1,0,2).to(device) #[seq_len, batch_size, horizon_size]\n",
    "            print(cur_series_covariate_tensor.shape, next_covariate_tensor.shape)\n",
    "            model_output = model(cur_series_covariate_tensor, next_covariate_tensor)\n",
    "            print(model_output.shape)\n",
    "            losses = []\n",
    "            for i, p in enumerate(desired_quantiles):\n",
    "                errors = cur_real_vals_tensor - model_output[:,:,:,i]\n",
    "                losses.append(torch.max((p-1)*errors, p*errors))\n",
    "            total_loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1)).to(device)\n",
    "            \n",
    "#             total_loss = torch.tensor([0.0]).to(device)\n",
    "#             for i in range(len(desired_quantiles)):\n",
    "#                 p = desired_quantiles[i]\n",
    "#                 errors = cur_real_vals_tensor - model_output[:,:,:,i]\n",
    "#                 cur_loss = torch.max((p-1)*errors, p*errors)\n",
    "#                 total_loss += torch.sum(cur_loss)\n",
    "\n",
    "            pbar.set_description(f\"Loss:{total_loss.item()}\")\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss_sum += total_loss.item()\n",
    "        epoch_loss_mean = epoch_loss_sum/ total_sample\n",
    "        if (epoch+1)%5 == 0:\n",
    "            print(f\"epoch_num {epoch+1}, current loss is: {epoch_loss_mean}\")\n",
    "\n",
    "def evaluate(model, device=torch.device('cuda'), covariate_size=3):\n",
    "    full_covariate_tensor = torch.tensor(train_covariate_df.to_numpy()).to(device)\n",
    "    next_covariate_tensor = torch.tensor(test_covariate_df.to_numpy().reshape(-1, horizon_size * covariate_size)).unsqueeze(dim=0).to(device)#[1,1,horizon_size * covariate_size]\n",
    "    results = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for colname in tqdm(train_target_df.columns):\n",
    "            input_target_tensor = torch.tensor(train_target_df[[colname]].to_numpy()).to(device)\n",
    "            input_target_covariate_tensor = torch.unsqueeze(torch.cat([input_target_tensor, full_covariate_tensor], dim=1), dim= 0).to(device) #[1, seq_len, 1+covariate_size]\n",
    "            input_target_covariate_tensor = input_target_covariate_tensor.permute(1,0,2).to(device) #[seq_len, 1, 1+covariate_size]\n",
    "            model_output = model(input_target_covariate_tensor, next_covariate_tensor)\n",
    "            \n",
    "            output_array = model_output.squeeze(0).cpu()\n",
    "            results.append(output_array)\n",
    "    # 预测结果，结构为 [时间序列数, horizon_size, quantile\n",
    "    predictions = torch.cat(results)\n",
    "    diff = torch.sum(torch.mul(predictions[:,:,1].T - torch.tensor(test_target_df.to_numpy()), predictions[:,:,1].T - torch.tensor(test_target_df.to_numpy()))).item()\n",
    "    test_rmse = np.sqrt(diff/test_target_df.shape[1])\n",
    "    return test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T09:16:04.744053Z",
     "start_time": "2024-02-18T09:16:04.722052Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30768/924670750.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhorizon_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfull_covariate_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_covariate_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnext_covariate_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_covariate_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhorizon_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcovariate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#[1,1,horizon_size * covariate_size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\")\n",
    "horizon_size = 30\n",
    "full_covariate_tensor = torch.tensor(train_covariate_df.to_numpy()).to(device)\n",
    "next_covariate_tensor = torch.tensor(test_covariate_df.to_numpy().reshape(-1, horizon_size * covariate_size)).unsqueeze(dim=0).to(device)#[1,1,horizon_size * covariate_size]\n",
    "results = []\n",
    "print(full_covariate_tensor.shape, next_covariate_tensor.shape)\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "for colname in tqdm(train_target_df.columns):\n",
    "    input_target_tensor = torch.tensor(train_target_df[[colname]].to_numpy()).to(device)\n",
    "    input_target_covariate_tensor = torch.unsqueeze(torch.cat([input_target_tensor, full_covariate_tensor], dim=1), dim= 0).to(device) #[1, seq_len, 1+covariate_size]\n",
    "    input_target_covariate_tensor = input_target_covariate_tensor.permute(1,0,2).to(device) #[seq_len, 1, 1+covariate_size]\n",
    "    print(input_target_covariate_tensor.shape)\n",
    "    print(next_covariate_tensor.shape)\n",
    "#         model_output = model(input_target_covariate_tensor, next_covariate_tensor)\n",
    "\n",
    "#         output_array = model_output.squeeze(0).cpu()\n",
    "#         results.append(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T08:46:30.534129Z",
     "start_time": "2024-02-18T08:34:22.986121Z"
    },
    "execution": {
     "iopub.execute_input": "2023-01-10T06:54:48.707915Z",
     "iopub.status.busy": "2023-01-10T06:54:48.707318Z",
     "iopub.status.idle": "2023-01-10T07:24:45.061124Z",
     "shell.execute_reply": "2023-01-10T07:24:45.059971Z",
     "shell.execute_reply.started": "2023-01-10T06:54:48.707874Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2648, 16, 4]) torch.Size([2648, 16, 90])\n",
      "torch.Size([2648, 16, 30, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:12.562996042517938:   4%|██▎                                                    | 1/24 [02:59<1:08:54, 179.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2648, 16, 4]) torch.Size([2648, 16, 90])\n",
      "torch.Size([2648, 16, 30, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:13.565271254480793:   8%|████▌                                                  | 2/24 [06:49<1:16:42, 209.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2648, 16, 4]) torch.Size([2648, 16, 90])\n",
      "torch.Size([2648, 16, 30, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:13.208515757016654:  12%|██████▉                                                | 3/24 [10:47<1:17:51, 222.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2648, 16, 4]) torch.Size([2648, 16, 90])\n",
      "torch.Size([2648, 16, 30, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss:8.788618543396083:  12%|███████                                                 | 3/24 [12:04<1:24:28, 241.36s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_INTERNAL_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30768/1986967534.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMQRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMQRNN_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_target_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_covariate_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# test_rmse = evaluate(model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(test_rmse)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30768/3985749148.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataset, desired_quantiles, batch_size, num_epochs, lr, device)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loss:{total_loss.item()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mepoch_loss_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR"
     ]
    }
   ],
   "source": [
    "model = MQRNN()\n",
    "train_dataset = MQRNN_dataset(train_target_df, train_covariate_df)\n",
    "train(model, train_dataset, batch_size=16, num_epochs=1, lr=0.0001)\n",
    "# test_rmse = evaluate(model)\n",
    "# print(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T07:08:19.373640Z",
     "start_time": "2024-02-20T07:08:18.922729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29ab8270fd0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(scaler.inverse_transform(target_df)[:, 0:100].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T07:43:45.434849Z",
     "start_time": "2024-02-20T07:43:45.416841Z"
    }
   },
   "outputs": [],
   "source": [
    "?torch.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T07:37:15.056788Z",
     "start_time": "2024-02-06T07:37:15.045854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2678, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_covariate_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
